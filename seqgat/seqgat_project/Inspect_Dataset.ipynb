{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a138c8e",
   "metadata": {},
   "source": [
    "\n",
    "# Inspect Dataset — Notebook 自检\n",
    "\n",
    "这个 Notebook 会：\n",
    "- 读取 `configs/seqgat_k5_st.yaml`（或你可以改为 Tactile 的 YAML）；\n",
    "- 用 `data/pt_dataset.py` 加载数据（会按 `k_last_frames` 自动裁到 5 帧）；\n",
    "- 对前几个样本做一致性检查（帧索引、空间/时序边、时序边占比、属性尺寸等）；\n",
    "- 输出数据集级别的统计。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5881842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiemengtong/anaconda3/envs/Tac-VGNN/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Processing...\n",
      "/Users/xiemengtong/seqgat_project/data/pt_dataset.py:43: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  f_u = (u // tip_num); f_v = (v // tip_num)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 144 samples | tip_num=331 | k_last_frames=5\n",
      "Sample[0] shapes: x (1655, 3) | y (2,)\n",
      "t: min/max 15 19\n",
      "edge_index_s: torch.Size([2, 9300])\n",
      "edge_index_t: torch.Size([2, 1192])\n",
      "edge_attr_t: torch.Size([1192, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, math, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from data.pt_dataset import load_dataset\n",
    "\n",
    "# 你也可以把它改成 'configs/tactile_gat_k5_s.yaml'\n",
    "CONFIG = 'configs/seqgat_k5_st.yaml'\n",
    "\n",
    "cfg = yaml.safe_load(open(CONFIG, 'r'))\n",
    "tip_num = int(cfg.get('tip_num', 331))\n",
    "k_last  = cfg.get('k_last_frames', 5)\n",
    "\n",
    "ds = load_dataset(\n",
    "    cfg['data_root'],\n",
    "    glob_pattern=cfg.get('glob','Train_data_list.pt'),\n",
    "    field_map=cfg.get('field_map',{}),\n",
    "    tip_num=tip_num,\n",
    "    k_last_frames=k_last,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(ds)} samples | tip_num={tip_num} | k_last_frames={k_last}\")\n",
    "if len(ds) > 0:\n",
    "    d0 = ds[0]\n",
    "    print('Sample[0] shapes:', 'x', tuple(d0.x.shape), '| y', tuple(d0.y.shape))\n",
    "    print('t: min/max', int(d0.t.min()), int(d0.t.max()))\n",
    "    print('edge_index_s:', getattr(d0,'edge_index_s', None).shape if hasattr(d0,'edge_index_s') else None)\n",
    "    print('edge_index_t:', getattr(d0,'edge_index_t', None).shape if hasattr(d0,'edge_index_t') else None)\n",
    "    print('edge_attr_t:', getattr(d0,'edge_attr_t', None).shape if hasattr(d0,'edge_attr_t') else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5daae7",
   "metadata": {},
   "source": [
    "## 定义检查函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0429ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inspect_sample(d, tip_num: int):\n",
    "    res = {}\n",
    "    N = d.x.size(0)\n",
    "    F = d.x.size(1)\n",
    "    t = d.t\n",
    "    t_min = int(t.min()); t_max = int(t.max())\n",
    "    K = t_max - t_min + 1\n",
    "\n",
    "    # 每帧节点数\n",
    "    counts = torch.bincount(t - t_min, minlength=K).cpu().numpy()\n",
    "\n",
    "    res['N_nodes'] = int(N)\n",
    "    res['F'] = int(F)\n",
    "    res['t_min'] = t_min\n",
    "    res['t_max'] = t_max\n",
    "    res['K_frames'] = int(K)\n",
    "    res['counts_first5'] = counts[:min(5, K)].tolist()\n",
    "    res['all_frames_have_tipnum_nodes'] = bool(np.all(counts == tip_num))\n",
    "\n",
    "    # 边检查\n",
    "    e_s = getattr(d, 'edge_index_s', None)\n",
    "    e_t = getattr(d, 'edge_index_t', None)\n",
    "    ea_t = getattr(d, 'edge_attr_t', None)\n",
    "\n",
    "    res['E_s'] = 0 if (e_s is None) else int(e_s.size(1))\n",
    "    res['E_t'] = 0 if (e_t is None) else int(e_t.size(1))\n",
    "\n",
    "    ok_s = True\n",
    "    if e_s is not None and e_s.numel() > 0:\n",
    "        ok_s = torch.all(t[e_s[0]] == t[e_s[1]]).item()\n",
    "    res['spatial_same_frame'] = bool(ok_s)\n",
    "\n",
    "    ok_t_frame = True\n",
    "    ok_t_jump  = True\n",
    "    median_jump = None\n",
    "    kept_frac = None\n",
    "    if e_t is not None and e_t.numel() > 0:\n",
    "        ok_t_frame = torch.all(t[e_t[1]] == t[e_t[0]] + 1).item()\n",
    "        jumps = (e_t[1] - e_t[0]).detach().cpu()\n",
    "        median_jump = int(torch.median(jumps).item())\n",
    "        ok_t_jump  = bool(torch.all(jumps == tip_num).item())\n",
    "        kept_frac = float(res['E_t'] / max((K-1)*tip_num, 1))\n",
    "    res['temporal_next_frame'] = bool(ok_t_frame)\n",
    "    res['temporal_v_minus_u_eq_tip'] = bool(ok_t_jump)\n",
    "    res['temporal_jump_median'] = median_jump\n",
    "    res['temporal_kept_fraction'] = kept_frac\n",
    "\n",
    "    if ea_t is not None:\n",
    "        res['edge_attr_t_shape'] = (int(ea_t.size(0)), int(ea_t.size(1)))\n",
    "        res['edge_attr_t_align'] = (ea_t.size(0) == (e_t.size(1) if e_t is not None else 0))\n",
    "    else:\n",
    "        res['edge_attr_t_shape'] = None\n",
    "        res['edge_attr_t_align'] = None\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec45dd6",
   "metadata": {},
   "source": [
    "## 检查前 3 个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ed46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 0 ---\n",
      "                     N_nodes: 1655\n",
      "                           F: 3\n",
      "                       t_min: 15\n",
      "                       t_max: 19\n",
      "                    K_frames: 5\n",
      "               counts_first5: [331, 331, 331, 331, 331]\n",
      "all_frames_have_tipnum_nodes: True\n",
      "                         E_s: 9300\n",
      "                         E_t: 1192\n",
      "          spatial_same_frame: True\n",
      "         temporal_next_frame: True\n",
      "   temporal_v_minus_u_eq_tip: True\n",
      "        temporal_jump_median: 331\n",
      "      temporal_kept_fraction: 0.9003021148036254\n",
      "           edge_attr_t_shape: (1192, 1)\n",
      "           edge_attr_t_align: True\n",
      "--- Sample 1 ---\n",
      "                     N_nodes: 1655\n",
      "                           F: 3\n",
      "                       t_min: 15\n",
      "                       t_max: 19\n",
      "                    K_frames: 5\n",
      "               counts_first5: [331, 331, 331, 331, 331]\n",
      "all_frames_have_tipnum_nodes: True\n",
      "                         E_s: 9300\n",
      "                         E_t: 1060\n",
      "          spatial_same_frame: True\n",
      "         temporal_next_frame: True\n",
      "   temporal_v_minus_u_eq_tip: True\n",
      "        temporal_jump_median: 331\n",
      "      temporal_kept_fraction: 0.8006042296072508\n",
      "           edge_attr_t_shape: (1060, 1)\n",
      "           edge_attr_t_align: True\n",
      "--- Sample 2 ---\n",
      "                     N_nodes: 1655\n",
      "                           F: 3\n",
      "                       t_min: 15\n",
      "                       t_max: 19\n",
      "                    K_frames: 5\n",
      "               counts_first5: [331, 331, 331, 331, 331]\n",
      "all_frames_have_tipnum_nodes: True\n",
      "                         E_s: 9300\n",
      "                         E_t: 1126\n",
      "          spatial_same_frame: True\n",
      "         temporal_next_frame: True\n",
      "   temporal_v_minus_u_eq_tip: True\n",
      "        temporal_jump_median: 331\n",
      "      temporal_kept_fraction: 0.850453172205438\n",
      "           edge_attr_t_shape: (1126, 1)\n",
      "           edge_attr_t_align: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_SHOW = min(3, len(ds))\n",
    "for i in range(N_SHOW):\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    info = inspect_sample(ds[i], tip_num)\n",
    "    for k, v in info.items():\n",
    "        print(f\"{k:>28}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc485de",
   "metadata": {},
   "source": [
    "## 数据集级别统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec97ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg nodes per sample: 1655.0\n",
      "Avg spatial edges Es: 9300.1\n",
      "Avg temporal edges Et: 1121.7\n",
      "Avg temporal kept fraction (Et/((K-1)*N)): 0.847\n",
      "Samples with bad spatial edges (not same-frame): 0\n",
      "Samples with bad temporal edges (not next-frame or jump!=tip_num): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tot_Es = tot_Et = 0\n",
    "tot_nodes = 0\n",
    "kept_fracs = []\n",
    "bad_spatial = 0\n",
    "bad_temporal = 0\n",
    "\n",
    "for d in ds:\n",
    "    info = inspect_sample(d, tip_num)\n",
    "    tot_Es += info['E_s']\n",
    "    tot_Et += info['E_t']\n",
    "    tot_nodes += info['N_nodes']\n",
    "    if info['temporal_kept_fraction'] is not None:\n",
    "        kept_fracs.append(info['temporal_kept_fraction'])\n",
    "    if not info['spatial_same_frame']:\n",
    "        bad_spatial += 1\n",
    "    if info['E_t'] > 0 and (not info['temporal_next_frame'] or not info['temporal_v_minus_u_eq_tip']):\n",
    "        bad_temporal += 1\n",
    "\n",
    "avg_Es = tot_Es / max(len(ds),1)\n",
    "avg_Et = tot_Et / max(len(ds),1)\n",
    "avg_nodes = tot_nodes / max(len(ds),1)\n",
    "avg_kept = (sum(kept_fracs)/len(kept_fracs)) if kept_fracs else None\n",
    "\n",
    "print(f\"Avg nodes per sample: {avg_nodes:.1f}\")\n",
    "print(f\"Avg spatial edges Es: {avg_Es:.1f}\")\n",
    "print(f\"Avg temporal edges Et: {avg_Et:.1f}\")\n",
    "print(f\"Avg temporal kept fraction (Et/((K-1)*N)): {avg_kept:.3f}\" if avg_kept is not None else \"No temporal edges found.\")\n",
    "print(f\"Samples with bad spatial edges (not same-frame): {bad_spatial}\")\n",
    "print(f\"Samples with bad temporal edges (not next-frame or jump!=tip_num): {bad_temporal}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tac-VGNN)",
   "language": "python",
   "name": "tac-vgnn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
